{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab223dd-0bff-42e9-b59d-15abf64f91da",
   "metadata": {
    "id": "3ab223dd-0bff-42e9-b59d-15abf64f91da",
    "outputId": "78c6445d-7290-4c73-9ae3-a7f9580d978f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface-hubNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda4\\lib\\site-packages (from huggingface-hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\programdata\\anaconda4\\lib\\site-packages (from huggingface-hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\programdata\\anaconda4\\lib\\site-packages (from huggingface-hub) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda4\\lib\\site-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda4\\lib\\site-packages (from huggingface-hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\programdata\\anaconda4\\lib\\site-packages (from huggingface-hub) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda4\\lib\\site-packages (from huggingface-hub) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda4\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda4\\lib\\site-packages (from requests->huggingface-hub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda4\\lib\\site-packages (from requests->huggingface-hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda4\\lib\\site-packages (from requests->huggingface-hub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda4\\lib\\site-packages (from requests->huggingface-hub) (2024.2.2)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "   ---------------------------------------- 0.0/447.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/447.5 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 112.6/447.5 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 286.7/447.5 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 447.5/447.5 kB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: huggingface-hub\n",
      "Successfully installed huggingface-hub-0.26.2\n"
     ]
    }
   ],
   "source": [
    "pip install huggingface-hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c5219e-56f5-4d36-b0a5-0ccd90f2f4c6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e4c5219e-56f5-4d36-b0a5-0ccd90f2f4c6",
    "outputId": "c6c78628-f375-419a-e988-77ad5dfbfc49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[{'question': 'Which city is recognized as the capital of India?', 'options': {'A': 'Delhi', 'B': 'Guwahati', 'C': 'Pune', 'D': 'Patna'}, 'correctAnswer': 'Delhi'}, {'question': 'Which of these landmarks is a significant historical site in Delhi?', 'options': {'A': 'Sanchi Stupa', 'B': 'Rang Ghar', 'C': 'Red Fort', 'D': 'Kamakhya Temple'}, 'correctAnswer': 'Red Fort'}, {'question': 'Among the following, which is classified as a Union Territory of India?', 'options': {'A': 'Assam', 'B': 'Delhi', 'C': 'Rajasthan', 'D': 'Jammu and Kashmir'}, 'correctAnswer': 'Delhi'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=\"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\")\n",
    "\n",
    "# Initial set of questions, options, and answers\n",
    "qa_data = [\n",
    "    {'question': 'What is the capital of India?', 'options': {'A': 'Delhi', 'B': 'Guwahati', 'C': 'Pune', 'D': 'Bihar'}, 'correctAnswer': 'Delhi'},\n",
    "    {'question': 'What is a historical monument located in Delhi?', 'options': {'A': 'Sanchi Stupa', 'B': 'Rang Ghar', 'C': 'Red Fort', 'D': 'Kamakhya Temple'}, 'correctAnswer': 'Red Fort'},\n",
    "    {'question': 'Which among the following is a Union Territory?', 'options': {'A': 'Assam', 'B': 'Delhi', 'C': 'Rajasthan', 'D': 'J&K'}, 'correctAnswer': 'Delhi'}\n",
    "]\n",
    "\n",
    "# Format the data as a prompt for the AI\n",
    "messages = [{\"role\": \"user\", \"content\": \"Reframe the following questions heavily and provide them in JSON format with only the questions, options, and correct answers:\"}]\n",
    "for item in qa_data:\n",
    "    question_prompt = {\n",
    "        \"question\": item[\"question\"],\n",
    "        \"options\": item[\"options\"],\n",
    "        \"correctAnswer\": item[\"correctAnswer\"]\n",
    "    }\n",
    "    messages.append({\"role\": \"user\", \"content\": json.dumps(question_prompt)})\n",
    "\n",
    "# Pass the messages to the model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-72B-Instruct\",\n",
    "    messages=messages,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# Attempt to parse the response as JSON\n",
    "try:\n",
    "    # Print the raw response to understand the format\n",
    "    raw_response = response.choices[0].message.content\n",
    "    # print(\"kk\")\n",
    "    # print(raw_response)\n",
    "\n",
    "    # Use a regex to extract JSON-like content from the response\n",
    "    json_match = re.search(r'(\\[.*\\])', raw_response, re.DOTALL)\n",
    "\n",
    "    if json_match:\n",
    "        json_content = json_match.group(1)\n",
    "        reframed_questions = json.loads(json_content)\n",
    "        output_json = json.dumps(reframed_questions, indent=2)\n",
    "        print(\"22\")\n",
    "        # print(output_json)\n",
    "        print(type(output_json))\n",
    "\n",
    "        #convert string to  object\n",
    "        json_output = json.loads(output_json)\n",
    "\n",
    "        #check new data type\n",
    "        print(type(json_output))\n",
    "        print(json_output)\n",
    "    else:\n",
    "        print(\"Error: No valid JSON found in the response.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: The model response was not valid JSON.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ce49c0-6ac1-4d93-9052-fc61dd63c75e",
   "metadata": {
    "id": "97ce49c0-6ac1-4d93-9052-fc61dd63c75e",
    "outputId": "82e8bb4f-730b-4caa-a74f-ed5cc44956ff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"question\": \"Which city serves as the capital of India?\",\n",
      "    \"options\": {\n",
      "      \"A\": \"Delhi\",\n",
      "      \"B\": \"Guwahati\",\n",
      "      \"C\": \"Pune\",\n",
      "      \"D\": \"Bihar\"\n",
      "    },\n",
      "    \"correctAnswer\": \"Delhi\"\n",
      "  },\n",
      "  {\n",
      "    \"question\": \"Identify the historical monument situated in Delhi from the options below.\",\n",
      "    \"options\": {\n",
      "      \"A\": \"Sanchi Stupa\",\n",
      "      \"B\": \"Rang Ghar\",\n",
      "      \"C\": \"Red Fort\",\n",
      "      \"D\": \"Kamakhya Temple\"\n",
      "    },\n",
      "    \"correctAnswer\": \"Red Fort\"\n",
      "  },\n",
      "  {\n",
      "    \"question\": \"Which of the following is designated as a Union Territory?\",\n",
      "    \"options\": {\n",
      "      \"A\": \"Assam\",\n",
      "      \"B\": \"Delhi\",\n",
      "      \"C\": \"Rajasthan\",\n",
      "      \"D\": \"J&K\"\n",
      "    },\n",
      "    \"correctAnswer\": \"Delhi\"\n",
      "  }\n",
      "]\n",
      "``` \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# question = \"What is the capital of France?\"\n",
    "# choices = \"A) London B) Paris C) Rome D) Madrid\"\n",
    "# prompt = f\"Question: {question}\\nChoices: {choices}\\nGive me a very subtle one line hint:\"\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "my_api_key = 'AIzaSyDWXF4luhWgxfAArlgk7_ybNhgz2etL9t0'\n",
    "genai.configure(api_key=my_api_key)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "\n",
    "\n",
    "questions_data = '''[\n",
    "    {'question': 'Where was the Summer Olympics 2024 held? ', 'options': {'A': 'Delhi', 'B': 'Guwahati', 'C': 'Pune', 'D': 'Bihar'}, 'correctAnswer': 'Delhi'},\n",
    "    {'question': 'Who was the wife of Louis XVI, the last King of France?', 'options': {'A': 'Sanchi Stupa', 'B': 'Rang Ghar', 'C': 'Red Fort', 'D': 'Kamakhya Temple'}, 'correctAnswer': 'Red Fort'},\n",
    "    {'question': 'Where is the Palace of Versailles located?', 'options': {'A': 'Assam', 'B': 'Delhi', 'C': 'Rajasthan', 'D': 'J&K'}, 'correctAnswer': 'Delhi'}\n",
    "] reframe the questions and generate them as json '''\n",
    "# prompt = \"give me the code in python to pass a dictionary having questions and answers as key value pairs into a prompt to generate content using the gemini api\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "response = model.generate_content(questions_data)\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8f24bcb-55cc-44ab-96d2-68ad32b53735",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8f24bcb-55cc-44ab-96d2-68ad32b53735",
    "outputId": "9f7ff61a-aac0-419a-9afe-d8ce0c2cda6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "[\n",
      "    {\n",
      "        \"hint\": \"The  capital  is  where  the  President 's  residence  and  Parliament  are  located .\"\n",
      "    },\n",
      "    {\n",
      "        \"hint\": \"C :  Red  Fort ,  a  significant  historical  monument  in  Delhi ,  India .\"\n",
      "    },\n",
      "    {\n",
      "        \"hint\": \"Del hi  is  known  for  its  historical  significance  and  political  status .\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "import json\n",
    "\n",
    "client = InferenceClient(api_key=\"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\")\n",
    "\n",
    "qa_data = 'what is the capital of india'\n",
    "# Initialize a list to collect the output\n",
    "output_data = []\n",
    "\n",
    "for qa in qa_data:\n",
    "    question = qa['question']\n",
    "    options = \", \".join([f\"{key}: {value}\" for key, value in qa['options'].items()])\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"{question} Options: {options} Provide a relevant minor hint of 10 words.\"}\n",
    "    ]\n",
    "\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"Qwen/Qwen2.5-72B-Instruct\",\n",
    "        messages=messages,\n",
    "        max_tokens=100,\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    hint = \"\"\n",
    "    for chunk in stream:\n",
    "        hint += chunk.choices[0].delta.content + \" \"\n",
    "\n",
    "    # Create a structured output for each question\n",
    "    output_data.append({\n",
    "\n",
    "\n",
    "        \"hint\": hint.strip()\n",
    "    })\n",
    "\n",
    "# Convert the output data to JSON format\n",
    "output = json.dumps(output_data, indent=4)\n",
    "\n",
    "# Print the JSON output\n",
    "print(type(output))\n",
    "print(output)\n",
    "# json_output = json.loads(output)\n",
    "# print(type(json_output))\n",
    "# print(json_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "t6sRCmmX5NLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t6sRCmmX5NLd",
    "outputId": "15531899-0715-4697-b221-56405d2ec357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New  Delhi  is  the  capital ,  a  bustling  city  with  historical  significance .  \n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=\"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\")\n",
    "\n",
    "# Define a single question\n",
    "question = 'What is the capital of India?'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"{question} Provide a minor hint of 10 words.\"}\n",
    "]\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-72B-Instruct\",\n",
    "    messages=messages,\n",
    "    max_tokens=100,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "hint = \"\"\n",
    "for chunk in stream:\n",
    "    hint += chunk.choices[0].delta.content + \" \"\n",
    "\n",
    "# Print only the hint as a string\n",
    "\n",
    "print(hint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3zrW4tSk-rg9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zrW4tSk-rg9",
    "outputId": "d91c3d3f-550d-4b22-ba97-0316d299881f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[{'question': \"Which river is known as the 'Ganga of the South'?\", 'options': {'A': 'Cauvery', 'B': 'Godavari', 'C': 'Krishna', 'D': 'Brahmaputra'}, 'correctAnswer': 'Cauvery'}, {'question': 'What is the national animal of India?', 'options': {'A': 'Elephant', 'B': 'Lion', 'C': 'Tiger', 'D': 'Bear'}, 'correctAnswer': 'Tiger'}, {'question': 'Which of the following states is known for its tea production?', 'options': {'A': 'Kerala', 'B': 'Assam', 'C': 'Gujarat', 'D': 'Maharashtra'}, 'correctAnswer': 'Assam'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question': \"Which river is known as the 'Ganga of the South'?\",\n",
       "  'options': {'A': 'Cauvery',\n",
       "   'B': 'Godavari',\n",
       "   'C': 'Krishna',\n",
       "   'D': 'Brahmaputra'},\n",
       "  'correctAnswer': 'Cauvery'},\n",
       " {'question': 'What is the national animal of India?',\n",
       "  'options': {'A': 'Elephant', 'B': 'Lion', 'C': 'Tiger', 'D': 'Bear'},\n",
       "  'correctAnswer': 'Tiger'},\n",
       " {'question': 'Which of the following states is known for its tea production?',\n",
       "  'options': {'A': 'Kerala', 'B': 'Assam', 'C': 'Gujarat', 'D': 'Maharashtra'},\n",
       "  'correctAnswer': 'Assam'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=\"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\")\n",
    "\n",
    "# Initial set of questions, options, and answers\n",
    "args = [\n",
    "    {'question': 'What is the capital of India?', 'options': {'A': 'Delhi', 'B': 'Guwahati', 'C': 'Pune', 'D': 'Bihar'}, 'correctAnswer': 'Delhi'},\n",
    "    {'question': 'What is a historical monument located in Delhi?', 'options': {'A': 'Sanchi Stupa', 'B': 'Rang Ghar', 'C': 'Red Fort', 'D': 'Kamakhya Temple'}, 'correctAnswer': 'Red Fort'},\n",
    "    {'question': 'Which among the following is a Union Territory?', 'options': {'A': 'Assam', 'B': 'Delhi', 'C': 'Rajasthan', 'D': 'J&K'}, 'correctAnswer': 'Delhi'}\n",
    "]\n",
    "\n",
    "qa_data=args\n",
    "\n",
    "# Format the data as a prompt for the AI\n",
    "messages = [{\"role\": \"user\", \"content\": \"Replace the above questions with new ones with different options and provide them in JSON format with only the questions, options, and correct answers:\"}]\n",
    "for item in qa_data:\n",
    "    question_prompt = {\n",
    "        \"question\": item[\"question\"],\n",
    "        \"options\": item[\"options\"],\n",
    "        \"correctAnswer\": item[\"correctAnswer\"]\n",
    "    }\n",
    "    messages.append({\"role\": \"user\", \"content\": json.dumps(question_prompt)})\n",
    "\n",
    "# Pass the messages to the model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-72B-Instruct\",\n",
    "    messages=messages,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# Attempt to parse the response as JSON\n",
    "try:\n",
    "    # Print the raw response to understand the format\n",
    "    raw_response = response.choices[0].message.content\n",
    "    # print(\"kk\")\n",
    "    # print(raw_response)\n",
    "\n",
    "    # Use a regex to extract JSON-like content from the response\n",
    "    json_match = re.search(r'(\\[.*\\])', raw_response, re.DOTALL)\n",
    "\n",
    "    if json_match:\n",
    "        json_content = json_match.group(1)\n",
    "        reframed_questions = json.loads(json_content)\n",
    "        output_json = json.dumps(reframed_questions, indent=2)\n",
    "        print(\"22\")\n",
    "        # print(output_json)\n",
    "        print(type(output_json))\n",
    "\n",
    "        #convert string to  object\n",
    "        json_output = json.loads(output_json)\n",
    "\n",
    "        #check new data type\n",
    "        print(type(json_output))\n",
    "        print(json_output)\n",
    "    else:\n",
    "        print(\"Error: No valid JSON found in the response.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: The model response was not valid JSON.\")\n",
    "\n",
    "\n",
    "json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Qgr6aw2FFBi6",
   "metadata": {
    "id": "Qgr6aw2FFBi6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ree/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "<class 'str'>\n",
      "<class 'list'>\n",
      "[{'question': 'What is a historical monument located in Delhi?', 'options': {'A': 'Sanchi Stupa', 'B': 'Rang Ghar', 'C': 'Red Fort', 'D': 'Kamakhya Temple'}, 'correctAnswer': 'Red Fort'}, {'question': 'Which among the following is an Union Territory?', 'options': {'A': 'Assam', 'B': 'Delhi', 'C': 'Rajasthan', 'D': 'J&K'}, 'correctAnswer': 'Delhi'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is a historical monument located in Delhi?',\n",
       "  'options': {'A': 'Sanchi Stupa',\n",
       "   'B': 'Rang Ghar',\n",
       "   'C': 'Red Fort',\n",
       "   'D': 'Kamakhya Temple'},\n",
       "  'correctAnswer': 'Red Fort'},\n",
       " {'question': 'Which among the following is an Union Territory?',\n",
       "  'options': {'A': 'Assam', 'B': 'Delhi', 'C': 'Rajasthan', 'D': 'J&K'},\n",
       "  'correctAnswer': 'Delhi'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = [{'correctAnswer': 'Delhi', 'options': {'A': 'Delhi', 'B': 'Guwahati', 'C': 'Pune', 'D': 'Bihar'}, 'question': 'What is the capital of India? '}, {'correctAnswer': 'Red Fort', 'options': {'A': 'Sanchi Stupa', 'B': 'Rang Ghar', 'C': 'Red Fort', 'D': 'Kamakhya Temple'}, 'question': 'What is a historical monument located in Delhi? '}, {'correctAnswer': 'Delhi', 'options': {'A': 'Assam', 'B': 'Delhi', 'C': 'Rajasthan', 'D': 'J&K'}, 'question': 'Which among the following is an Union Territory?'}]\n",
    "\n",
    "import json\n",
    "import re\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=\"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\")\n",
    "qa_data=args\n",
    "\n",
    "# Format the data as a prompt for the AI\n",
    "messages = [{\"role\": \"user\", \"content\": \"Replace the above questions with new ones with different options and provide them in JSON format with only the questions, options, and correct answers:\"}]\n",
    "for item in qa_data:\n",
    "    question_prompt = {\n",
    "        \"question\": item[\"question\"],\n",
    "        \"options\": item[\"options\"],\n",
    "        \"correctAnswer\": item[\"correctAnswer\"]\n",
    "    }\n",
    "    messages.append({\"role\": \"user\", \"content\": json.dumps(question_prompt)})\n",
    "\n",
    "# Pass the messages to the model\n",
    "response = client.chat.completions.create(\n",
    "    model=\"Qwen/Qwen2.5-72B-Instruct\",\n",
    "    messages=messages,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "# Attempt to parse the response as JSON\n",
    "try:\n",
    "    # Print the raw response to understand the format\n",
    "    raw_response = response.choices[0].message.content\n",
    "    # print(\"kk\")\n",
    "    # print(raw_response)\n",
    "\n",
    "    # Use a regex to extract JSON-like content from the response\n",
    "    json_match = re.search(r'(\\[.*\\])', raw_response, re.DOTALL)\n",
    "\n",
    "    if json_match:\n",
    "        json_content = json_match.group(1)\n",
    "        reframed_questions = json.loads(json_content)\n",
    "        output_json = json.dumps(reframed_questions, indent=2)\n",
    "        print(\"22\")\n",
    "        # print(output_json)\n",
    "        print(type(output_json))\n",
    "\n",
    "        #convert string to  object\n",
    "        json_output = json.loads(output_json)\n",
    "\n",
    "        #check new data type\n",
    "        print(type(json_output))\n",
    "        print(json_output)\n",
    "    else:\n",
    "        print(\"Error: No valid JSON found in the response.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: The model response was not valid JSON.\")\n",
    "\n",
    "\n",
    "json_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66c8de-65f0-458e-93d0-00f8945b978c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
